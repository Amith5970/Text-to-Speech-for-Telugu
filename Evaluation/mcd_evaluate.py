# -*- coding: utf-8 -*-
"""MCD_EVALUATE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nFFkQ5gNtExL6gbiFC9Y-pudhk35HJCO
"""

pip install pyworld

pip install pysptk

from google.colab import drive
drive.mount('/content/drive')

import os
import math
import glob
import librosa
import pyworld
import pysptk
import numpy as np
import matplotlib.pyplot as plot

SAMPLING_RATE = 22050
FRAME_PERIOD = 5.0

def load_wav(wav_file, sr):

    wav, _ = librosa.load(wav_file, sr=sr, mono=True)

    return wav

def MCD(x, y):
    log_spec_dB_const = 10.0 / math.log(10.0) * math.sqrt(2.0)
    diff = x - y

    return log_spec_dB_const * math.sqrt(np.inner(diff, diff))

ORIGINAL_PATH ='/content/drive/My Drive/AI4BHARAT/Testing/ground-truth/'
SYNTHESIZED_PATH = '/content/drive/My Drive/AI4BHARAT/Testing/Synthesized/'

Org_speech_wav_file_paths = glob.glob(ORIGINAL_PATH+'/*')
Synth_speech_wav_file_paths = glob.glob(SYNTHESIZED_PATH+'/*')

Org_speech_wav_file_paths[:]
Synth_speech_wav_file_paths[:]

def MCEP(wavfile, mcep_target_directory, alpha=0.65, fft_size=512, mcep_size=24):

    if not os.path.exists(mcep_target_directory):
        os.makedirs(mcep_target_directory)

    loaded_wav_file = load_wav(wavfile, sr=SAMPLING_RATE)


    _, spectral_envelop, _ = pyworld.wav2world(loaded_wav_file.astype(np.double), fs=SAMPLING_RATE,
                                   frame_period=FRAME_PERIOD, fft_size=fft_size)


    mcep = pysptk.sptk.mcep(spectral_envelop, order=mcep_size, alpha=alpha, maxiter=0,
                           etype=1, eps=1.0E-8, min_det=0.0, itype=3)

    fname = os.path.basename(wavfile).split('.')[0]
    np.save(os.path.join(mcep_target_directory, fname + '.npy'),
            mcep,
            allow_pickle=False)

alpha = 0.65
fft_size = 512
mcep_size = 24

dir_org_speech_wav = glob.glob(ORIGINAL_PATH+'/*')
dir_org_speech_mcep = ORIGINAL_PATH+'stats/mceps_trg'
dir_converted_speech_wav = glob.glob(SYNTHESIZED_PATH+'/*')
dir_converted_speech_mcep =SYNTHESIZED_PATH+'stats/mceps_conv'

for wav in dir_org_speech_wav:
    MCEP(wav, dir_org_speech_mcep, fft_size=fft_size, mcep_size=mcep_size)
for wav in dir_converted_speech_wav:
    MCEP(wav, dir_converted_speech_mcep, fft_size=fft_size, mcep_size=mcep_size)

def mcd_cal(mcep_org_files, mcep_synth_files, MCD):
    min_cost_tot = 0.0
    total_frames = 0

    for i in mcep_org_files:
        x=0
        for j in mcep_synth_files:

            split_org_file,  split_synth_file = os.path.basename(i).split('_'), os.path.basename(j).split('_')
            org_speaker, org_speaker_id = split_org_file[0], split_org_file[-1]
            synth_speaker, synth_speaker_id = split_synth_file[0], split_synth_file[-1]

            x+=1
            if org_speaker==synth_speaker and org_speaker_id==synth_speaker_id:

                org_mcep_npy=np.load(i)

                frame_no = len(org_mcep_npy)
                synth_mcep_npy = np.load(j)

                min_cost, _ = librosa.sequence.dtw(org_mcep_npy[:, 1:].T, synth_mcep_npy[:, 1:].T,
                                                   metric=MCD)

                min_cost_tot += np.mean(min_cost)

                total_frames += frame_no

                #print(j,"    ",i,"     ",x,"   ",min_cost_tot,"   ",total_frames)

    mcd = min_cost_tot/total_frames
    return mcd, total_frames

org_file = glob.glob(ORIGINAL_PATH+'/mceps_trg/*')
synth_file= glob.glob(SYNTHESIZED_PATH+'/mceps_conv/*')

cost_function = MCD

mcd, frames_used = mcd_cal(org_file, synth_file, cost_function)



print(f' MCD = {mcd} dB and total of frames {frames_used}')



